import os
import uuid
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

from tools.mcp_base import tool

# .envì—ì„œ ì½ì–´ì˜¤ê¸°
MUSIC_TEXT_EMBEDDING_API_URL = os.getenv("MUSIC_TEXT_EMBEDDING_API_URL")
TEXT_MUSIC_EMBEDDING_API_URL = os.getenv("TEXT_MUSIC_EMBEDDING_API_URL")


class MusicTextEmbeddingInput(BaseModel):
    """ìŒì•…-í…ìŠ¤íŠ¸ ì„ë² ë”© ë„êµ¬ì— ëŒ€í•œ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""

    audio_path: Optional[str] = Field(
        default=None, description="Path to the audio file to generate embeddings for"
    )
    text_prompts: Optional[List[Dict[str, str]]] = Field(
        default=None,
        description="List of stem prompts for batch embedding",
    )


# ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜
class MusicTextEmbeddingOutput(BaseModel):
    """ìŒì•…-í…ìŠ¤íŠ¸ ì„ë² ë”© ë„êµ¬ì— ëŒ€í•œ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ"""

    music_text_joint_embedding: List[Dict[str, Any]] = Field(
        description="Cross-modal embedding vector or dictionary of vectors"
    )


# ë¹„ë™ê¸° ìŒì•…-í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜
async def get_embedding_async(
    audio_path: Optional[str] = None,
    input_text: Optional[str] = None,
) -> List[float]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ë¡œë¶€í„° ë¹„ë™ê¸°ì ìœ¼ë¡œ í¬ë¡œìŠ¤ëª¨ë‹¬ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        import aiohttp

        # ì…ë ¥ ê°’ì— ë”°ë¥¸ API uri ê²°ì •
        if input_text is None and audio_path is not None:
            # ì˜¤ë””ì˜¤ë§Œ ìˆëŠ” ê²½ìš° - ìŒì•…->í…ìŠ¤íŠ¸ ì„ë² ë”©
            api_url = MUSIC_TEXT_EMBEDDING_API_URL

            # ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ë° FormData ì¤€ë¹„
            if not os.path.exists(audio_path):
                print(f"Error: File not found: {audio_path}")
                return []

            with open(audio_path, "rb") as audio_file:
                file_content = audio_file.read()

            data = aiohttp.FormData()
            unique_filename = f"{uuid.uuid4().hex}.mp3"
            data.add_field("file", file_content, filename=unique_filename)

            # ë¹„ë™ê¸° API í˜¸ì¶œ (FormData)
            async with aiohttp.ClientSession() as session:
                async with session.post(api_url, data=data) as response:
                    response.raise_for_status()
                    result = await response.json()
                    embedding_vector = result.get("mtrppembed", [])

                    return embedding_vector

        elif input_text is not None and audio_path is None:
            # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš° - JSON í˜•ì‹ìœ¼ë¡œ ì „ì†¡
            api_url = TEXT_MUSIC_EMBEDDING_API_URL
            # JSON ìš”ì²­ ì¤€ë¹„
            headers = {"Content-Type": "application/json"}
            json_data = {"prompt": input_text}

            # ë¹„ë™ê¸° API í˜¸ì¶œ (JSON)
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    api_url, json=json_data, headers=headers
                ) as response:
                    response.raise_for_status()
                    result = await response.json()
                    embedding_vector = result.get("mtrppembed", [])

                    return embedding_vector

        else:
            # ë‘ ì…ë ¥ì´ ëª¨ë‘ ìˆëŠ” ê²½ìš° (FormData + prompt íŒŒë¼ë¯¸í„°)
            if input_text is not None and audio_path is not None:
                print(
                    "Both audio and text provided, using music-to-text API as default"
                )
                api_url = MUSIC_TEXT_EMBEDDING_API_URL

                # íŒŒì¼ í™•ì¸ ë° ì½ê¸°
                if not os.path.exists(audio_path):
                    print(f"Error: File not found: {audio_path}")
                    return []

                with open(audio_path, "rb") as audio_file:
                    file_content = audio_file.read()

                # FormData ì¤€ë¹„
                data = aiohttp.FormData()
                unique_filename = f"{uuid.uuid4().hex}.mp3"
                data.add_field("file", file_content, filename=unique_filename)
                data.add_field("prompt", input_text)  # "prompt" íŒŒë¼ë¯¸í„° ì‚¬ìš©

                # ë¹„ë™ê¸° API í˜¸ì¶œ
                async with aiohttp.ClientSession() as session:
                    async with session.post(api_url, data=data) as response:
                        response.raise_for_status()
                        result = await response.json()
                        embedding_vector = result.get("mtrppembed", [])

                        return embedding_vector
            else:
                print("Error: Neither audio nor text provided")
                return []

    except Exception as e:
        error_msg = f"Error in get_embedding_async: {str(e)}"
        print(error_msg)
        print(f"API URL: {api_url if 'api_url' in locals() else 'unknown'}")
        return []


# ìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± í•¨ìˆ˜ ì¶”ê°€
async def get_stem_embeddings(
    text_prompts: List[Dict[str, str]],
) -> List[Dict[str, Any]]:
    """
    ìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ìŒì•…-í…ìŠ¤íŠ¸ ì„ë² ë”© ë²¡í„° ìƒì„±

    Args:
        text_prompts (List[Dict[str, str]]): ìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[Dict[str, Any]]: ì„ë² ë”©ì´ í¬í•¨ëœ ìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    embedding_outputs = []

    # ê° ìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬ ë¯¸ì§€ì›)
    for embedding_input in text_prompts:
        try:
            if embedding_input["uri"] == "":
                audio_path = None

            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
            embedding_vector = await get_embedding_async(
                audio_path=audio_path, input_text=embedding_input["text"]
            )

            # ê²°ê³¼ ì €ì¥
            embedding_outputs.append(
                {
                    "category": embedding_input["category"],
                    "text": embedding_input["text"],
                    "uri": embedding_input["uri"],
                    "embedding": embedding_vector,
                }
            )

        except Exception as e:
            print(f"Error processing stem {embedding_input['category']}: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            embedding_outputs.append(
                {
                    "category": embedding_input["category"],
                    "text": embedding_input["text"],
                    "uri": embedding_input["uri"],
                    "embedding": None,
                }
            )
    return embedding_outputs


@tool(
    name="get_music_text_joint_embedding",
    description="Generates cross-modal embedding vectors between music and text",
    input_schema=MusicTextEmbeddingInput,
    output_schema=MusicTextEmbeddingOutput,
)
async def get_music_text_joint_embedding(params) -> MusicTextEmbeddingOutput:
    """
    Generate cross-modal embeddings between music and text

    Args:
        params: Dictionary containing all parameters:
            - text_prompts: List of stem prompts for batch embedding
            - task_id: Task identifier

    Returns:
        Cross-modal embedding results
    """
    print("\nâœ… **GET_MUSIC_TEXT_JOINT_EMBEDDING** FUNCTION CALLED!")
    # print("ğŸµ get_music_text_joint_embedding called with params:", params)

    # ê²€ì¦ëœ ë°ì´í„°ì—ì„œ ê°’ ì¶”ì¶œ
    text_prompts = params.get("text_prompts", [])
    # audio_path = params.get("audio_path", None)

    try:
        # ì…ë ¥ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬ ë¶„ê¸°
        if text_prompts and isinstance(text_prompts, list):
            music_text_joint_embeddings = await get_stem_embeddings(text_prompts)
            return MusicTextEmbeddingOutput(
                music_text_joint_embedding=music_text_joint_embeddings
            )

    except Exception as e:
        error_msg = f"Error in music_text_joint_embedding: {str(e)}"
        print(error_msg)


if __name__ == "__main__":
    import asyncio

    async def test_embedding():
        result = await get_music_text_joint_embedding(
            {"text_prompts": [{"category": "test", "text": "test", "uri": ""}]}
        )
        print(result)

    asyncio.run(test_embedding())
